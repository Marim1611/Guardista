{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract functions from LL files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import CodePreprocessing as preprocessing\n",
        "import json\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# ----------------- user functions  --------------------\n",
        "preprocessing.functions_preprocessing( llvm_file='pairs/UserCode/UserCode.ll', json_file='UserCode' )\n",
        "with open( 'UserCode.json', 'r' ) as f:\n",
        "    user_code = json.load(f) \n",
        "\n",
        "# ----------------- Vulnerable functions ------------------\n",
        "# Reading all vulnerable codes from the LLVM files\n",
        "\n",
        "vuln_codes_path= 'pairs/ourVulnCodes/'\n",
        "\n",
        "if not os.path.exists(vuln_codes_path+'/jsons'):\n",
        "    os.makedirs(vuln_codes_path+'/jsons')\n",
        "\n",
        "for file in os.listdir(vuln_codes_path):\n",
        "    if file.endswith(\".ll\"):\n",
        "        file_name= file.split('.')[0]\n",
        "        preprocessing.functions_preprocessing( llvm_file=vuln_codes_path+file, json_file=vuln_codes_path+'/jsons/'+file_name )\n",
        "\n",
        "vulnerable_code= dict()\n",
        "for file in os.listdir(vuln_codes_path+'/jsons'):\n",
        "    if file.endswith(\".json\"):\n",
        "        with open( vuln_codes_path+'/jsons/'+file, 'r' ) as f:\n",
        "            vulnerable_code.update(json.load(f)) \n",
        "\n",
        "vulnerable_function=[]\n",
        "for key in vulnerable_code:\n",
        "    vulnerable_function.append(vulnerable_code[key])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of vulnerable functions:  12\n"
          ]
        }
      ],
      "source": [
        "print('Number of vulnerable functions: ',len(vulnerable_function))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAUxk6Oql4zr",
        "outputId": "075923bf-4d53-4a48-f894-cfae71e0e118"
      },
      "outputs": [],
      "source": [
        "import matchers as matcher\n",
        "import LLNormalizer as normalizer\n",
        "import Winnowing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_function_vulnerable(threshold,score1,score2,score3):\n",
        "    return score1 > threshold and score2 > threshold and score3 > threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#applying KNN but with similarity measures, we take the top 3 scores in all similarity measures, if those top 3 passed the threshold, we do the ultimate test, MOSS.\n",
        "#K here equals 3\n",
        "\n",
        "threshold=0.7\n",
        "k=3\n",
        "\n",
        "#this is a dictionary of key: vulnerable function (which is in our database)        value: code_scores for this vulnerable function (and the User Function)\n",
        "Vulnerable_Matches = dict()\n",
        "\n",
        "for k,v in vulnerable_code.items():\n",
        "    vuln_func = v\n",
        "    vuln_head=k\n",
        "    code_scores=dict()\n",
        "\n",
        "\n",
        "    for key in user_code:\n",
        "        fn=user_code[key] \n",
        "        #fn=normalizer.NormalizeLLVM(fn)\n",
        "\n",
        "        jaro_winkler=matcher.jaro_winkler_similarity(fn, vuln_func)\n",
        "        levenshtein=matcher.levenshtein_similarity(fn, vuln_func)\n",
        "        ratcliff_obershelp=matcher.ratcliff_obershelp_similarity(fn, vuln_func)\n",
        "        trigram=matcher.trigram_similarity(fn, vuln_func)\n",
        "        sorensen_dice=matcher.sorensen_dice_similarity(fn, vuln_func)\n",
        "        jaccard_distance=matcher.jaccard_distance(fn, vuln_func)\n",
        "\n",
        "        scores=[jaro_winkler,levenshtein,ratcliff_obershelp,trigram,sorensen_dice,jaccard_distance]\n",
        "        scores.sort(reverse=True) \n",
        "        code_scores[key]=scores\n",
        "    \n",
        "    Vulnerable_Matches[vuln_head] = code_scores\n",
        "\n",
        "with open('code_scores.json', 'w') as f:\n",
        "    f.write(json.dumps(Vulnerable_Matches, indent=6))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MOSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Vulnerable function found: define void @\"CWE23_Relative_Path_Traversal__char_environment_fopen_41::bad\"() local_unnamed_addr {\n",
            "\n",
            "MOSS Caught this <3 !!!\n",
            "Accuracy_Metric 1 = 0.9059233449477352  ||  Accuracy_Metric 2 = 0.5241935483870968\n",
            "hits: 4420 , misses: 459, misses2: 4012\n",
            "-----------------------\n",
            "\n",
            "\n",
            "Vulnerable function found: define void @\"CWE23_Relative_Path_Traversal__char_environment_fopen_41::goodG2B\"() local_unnamed_addr {\n",
            "\n",
            "MOSS Caught this <3 !!!\n",
            "Accuracy_Metric 1 = 0.8165194164783234  ||  Accuracy_Metric 2 = 0.5601917113053284\n",
            "hits: 3974 , misses: 893, misses2: 3120\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "#Candidate_Functions is a list of tuples, each containing a possible Match. A Match means User Function matching a Vulnerable Function\n",
        "Candidate_Functions = []\n",
        "for k,v in vulnerable_code.items():\n",
        "    vuln_func = v\n",
        "    vuln_head = k\n",
        "\n",
        "    #Normalizing the vulnerable function with us (not user code)\n",
        "    normalizedvuln = normalizer.NormalizeLLVM(vuln_func)\n",
        "\n",
        "    #for each function passing the threshold, do MOSS.\n",
        "    for key in Vulnerable_Matches[vuln_head]:\n",
        "        code_scores = Vulnerable_Matches[vuln_head]\n",
        "        if check_function_vulnerable(threshold,code_scores[key][0],code_scores[key][1],code_scores[key][2]):\n",
        "            fn = user_code[key]\n",
        "\n",
        "            #sometimes normalizing behaves good, sometimes bad.\n",
        "            normalizedfn = normalizer.NormalizeLLVM(fn)\n",
        "            \n",
        "            #MOSS Metrics (defined in Winnowing.py), Parameters passed: k=20, ws = 10, P=10\n",
        "            MOSS_Acc_metric1, MOSS_Acc_metric2, hits, misses1, misses2 = Winnowing.diff(normalizedfn, normalizedvuln, K= 20, WindowSize= 10, P= 10)\n",
        "            \n",
        "            print(\"\\n\\nVulnerable function found:\",key)\n",
        "            #Candidate_Functions containg a tuple of (original function head, vulnerable function name (which is stored with us))\n",
        "            Candidate_Functions.append((re.findall('(@.*)\\(', key)[0]  ,  re.findall('(@.*)\\(', vuln_head)[0]))\n",
        "\n",
        "            #MOSS Thresholds, 0.7 for Metric1, 0.7 for Metric2, those thresholds are highly dependent on the vulnerability type unfortunately.\n",
        "            if(MOSS_Acc_metric1>0.7 or MOSS_Acc_metric2>0.7):\n",
        "                print(f\"MOSS Caught this <3 !!!\")\n",
        "                print(f\"Accuracy_Metric 1 = {MOSS_Acc_metric1}  ||  Accuracy_Metric 2 = {MOSS_Acc_metric2}\\nhits: {hits} , misses: {misses1}, misses2: {misses2}\")\n",
        "            print('-----------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(Candidate_Functions)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph matching ان شاء الله"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['python', 'D:/Guardista/IrToCFGs/generate_subgraphs.py', '0', 'D:/Guardista/Localizer/Common/pairs', 'D:/Guardista/Localizer/Common/pairs'], returncode=0)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import graph\n",
        "import os\n",
        "import re\n",
        "from subprocess import run\n",
        "import pathlib\n",
        "import json\n",
        "\n",
        "#Path to Marim's script generate_subgraphs.py\n",
        "absPathtoCFGScript = str(os.path.abspath(\"../../IrToCFGs/generate_subgraphs.py\")).replace(\"\\\\\", \"/\")\n",
        "absPathtoCFGScript = list(absPathtoCFGScript)\n",
        "absPathtoCFGScript[0] = absPathtoCFGScript[0].upper()\n",
        "absPathtoCFGScript = ''.join(absPathtoCFGScript)\n",
        "\n",
        "\n",
        "#Path to the pairs folder in this directory\n",
        "absPathtoPairsFolder = (str(os.getcwd())+\"/pairs\").replace(\"\\\\\", \"/\")\n",
        "absPathtoPairsFolder = list(absPathtoPairsFolder)\n",
        "absPathtoPairsFolder[0] = absPathtoPairsFolder[0].upper()\n",
        "absPathtoPairsFolder = ''.join(absPathtoPairsFolder)\n",
        "\n",
        "#run CFG script on all subfolders inside pairs folder\n",
        "run([\"python\",absPathtoCFGScript, \"0\", absPathtoPairsFolder , absPathtoPairsFolder])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO THIS CELL assumes that the CFG of the vulnerable code is put inside 1 folder only, rather, Marim makes a subfolder for each LLVM file and each subfolder\n",
        "#Contains the CFG (s) for this LLVM file,\n",
        "#so the TODO is to loop through all subfolders and store the graphs in the list 'ourGraphs'\n",
        "\n",
        "#Prepare graphs for Vulnerable code, precompute them and store them in a list\n",
        "#Vulnerable code (we are storing) is put inside a folder called ourVulnCodes, and the corresponding CFGs is inside a folder called ourVulnCodes_subgraphs/VulnerableCode_subgraphs\n",
        "VulnerableCodeSubgraphsFolder = absPathtoPairsFolder + \"/ourVulnCodes_subgraphs/\"\n",
        "\n",
        "#List containing graphs of each precomputed Vulnerable Code\n",
        "ourGraphs = []\n",
        "\n",
        "for currentpath, folders, jsonfiles in os.walk(VulnerableCodeSubgraphsFolder):\n",
        "\n",
        "    for jsonfile in jsonfiles:\n",
        "        fulljsonFilePath = currentpath+'/'+jsonfile\n",
        "       \n",
        "        with open(fulljsonFilePath) as f:\n",
        "            jsonDict= json.load(f)\n",
        "        \n",
        "        functionName = jsonDict[\"function_name\"].replace('\\\\', '')\n",
        "        newGraph = graph.Graph()\n",
        "        newGraph.readGraphFromJSON(fulljsonFilePath)\n",
        "        ourGraphs.append(newGraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "we are trying to find the json file containing the name of the candidate functions (we will not compute CFG of EVERY possible function, rather just the candidate functions),\n",
        "if we found a json of a candidate function, we compute its graph and perform the matching.\n",
        "\n",
        "candidate functions are the functions that passed MOSS\n",
        "'''\n",
        "\n",
        "\n",
        "UserCodeSubgraphsFolder = absPathtoPairsFolder + \"/UserCode_subgraphs/UserCode_subgraphs\"\n",
        "\n",
        "final_Matched_Functions = []\n",
        "\n",
        "allFiles = os.listdir(UserCodeSubgraphsFolder)\n",
        "for jsonfile in allFiles:\n",
        "    fulljsonFilePath = UserCodeSubgraphsFolder+'/'+jsonfile\n",
        "    if(pathlib.Path(jsonfile).suffix != \".json\"):\n",
        "        continue\n",
        "    with open(fulljsonFilePath) as f:\n",
        "        jsonDict = json.load(f)\n",
        "    functionName = jsonDict[\"function_name\"].replace('\\\\', '')\n",
        "\n",
        "    if(functionName in [i[0] for i in Candidate_Functions]):              #check if the function name is inside Candidate Functions\n",
        "        #Construct User Graph and Perform Matching\n",
        "        UserCodeGraph = graph.Graph()\n",
        "        UserCodeGraph.readGraphFromJSON(fulljsonFilePath)\n",
        "        MatchPairs = graph.matchGraphWithListOfGraphs(UserCodeGraph , ourGraphs, otherWayAround=True)\n",
        "        \n",
        "        #MatchPairs is a list of Tuples, each Tuples contains the UserFunction Name and the Function Name stored in our Database\n",
        "        if(MatchPairs):\n",
        "            final_Matched_Functions.append(MatchPairs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Matches الحمد لله"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[('@\"CWE23_Relative_Path_Traversal__char_environment_fopen_41::bad\"', '@\"CWE23_Relative_Path_Traversal__char_environment_fopen_18::bad\"'), ('@\"CWE23_Relative_Path_Traversal__char_environment_fopen_41::bad\"', '@\"CWE23_Relative_Path_Traversal__char_environment_fopen_18::bad\"')]]\n"
          ]
        }
      ],
      "source": [
        "print(final_Matched_Functions)\n",
        "# NOTICE NO FALSE POSITIVES NOR FALSE NEGATIVES <3 <3 <3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Cleanup\n",
        "\n",
        "import os\n",
        "files = os.listdir('./')\n",
        "files = [ fi for fi in files if fi.endswith(\".json\")]\n",
        "for f in files:\n",
        "    os.remove(f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
