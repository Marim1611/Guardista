from stellargraph.mapper import (
    CorruptedGenerator,
    FullBatchNodeGenerator,
    GraphSAGENodeGenerator,
    HinSAGENodeGenerator,
    ClusterNodeGenerator,
)
from stellargraph import StellarGraph
from stellargraph.layer import GCN, DeepGraphInfomax, GraphSAGE, GAT, APPNP, HinSAGE

from stellargraph import datasets
from stellargraph.utils import plot_history

import pandas as pd
from matplotlib import pyplot as plt
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.manifold import TSNE
# from IPython.display import display, HTML

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
from tensorflow.keras import Model

import numpy as np
import os
import csv


# PUT CVE CLASS
cve = 'SAFE_23'
with open('features_matrices/features_matrices_' + cve + '.npy', 'rb') as f:
    features_matrices_list = np.load(f,  allow_pickle=True)

for i, mat in enumerate(features_matrices_list):
    print('file' ,i ,'o/p',mat.shape)

print('number of matrices', len(features_matrices_list))

graphs_representaions_path = 'graphs_representations.csv'

features_number = features_matrices_list[0].shape[1] #not used bec the embeddings size turns out to be 128

features_names = []
for i in range(128):
    features_names.append('X'+str(i))
features_names.append('y')

# Using a with open() statement will automatically close a file once the block has completed
if not os.path.exists(graphs_representaions_path):
    with open(graphs_representaions_path, 'a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(features_names)


# PUT CVE CLASS
edges_directory_path = 'CFGs/'+ cve +'_CFGs/edges_' + cve

i = 0
for filename in os.listdir(edges_directory_path):
    f = os.path.join(edges_directory_path, filename)

    if os.path.isfile(f):
        # calling clear_session() when creating models in a loop to reset all state generated by Keras.
        tf.keras.backend.clear_session()

        print(f)

        features_matrix = features_matrices_list[i]
        
        # Read in edges
        edges = pd.read_csv(f)
        edges.columns = ['source', 'target'] # renaming for StellarGraph compatibility
        col=np.array(edges['target'], np.int16)
        edges['target']=col
        # print(edges)
        # print(edges.shape)

        node_features = pd.DataFrame(features_matrix)
        # print(node_features)
        # print(node_features.shape)

        G = StellarGraph(node_features, edges)
        # print(G.info())

        fullbatch_generator = FullBatchNodeGenerator(G, sparse=False)
        gcn_model = GCN(layer_sizes=[128], activations=["relu"], generator=fullbatch_generator)

        corrupted_generator = CorruptedGenerator(fullbatch_generator)
        gen = corrupted_generator.flow(G.nodes())

        infomax = DeepGraphInfomax(gcn_model, corrupted_generator)
        x_in, x_out = infomax.in_out_tensors()

        model = Model(inputs=x_in, outputs=x_out)
        model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer=Adam(lr=1e-3))
        epochs = 100

        es = EarlyStopping(monitor="loss", min_delta=0, patience=20)
        history = model.fit(gen, epochs=epochs, verbose=0, callbacks=[es])
        # print(history)
        x_emb_in, x_emb_out = gcn_model.in_out_tensors()
        print(x_emb_out.shape)

        # for full batch models, squeeze out the batch dim (which is 1)
        x_out = tf.squeeze(x_emb_out, axis=0)
        emb_model = Model(inputs=x_emb_in, outputs=x_out)
       
        #-----------------------------------------------------------------------------------------
        # train_subjects, test_subjects = model_selection.train_test_split(
        #     node_features, train_size=0.1, test_size=None, stratify=node_features
        # )

        # test_gen = fullbatch_generator.flow(test_subjects.index)
        # train_gen = fullbatch_generator.flow(train_subjects.index)

        # test_embeddings = emb_model.predict(test_gen)
        # train_embeddings = emb_model.predict(train_gen)

        # lr = LogisticRegression(multi_class="auto", solver="lbfgs")
        # lr.fit(train_embeddings, train_subjects)

        # y_pred = lr.predict(test_embeddings)
        # gcn_acc = (y_pred == test_subjects).mean()
        # print(f"Test classification accuracy: {gcn_acc}")
        #--------------------------------------------------------------------------------------------

        targets = np.zeros(features_matrix.shape[0])
        all_embeddings = emb_model.predict(fullbatch_generator.flow(G.nodes(), targets))
        print(all_embeddings.shape)

        graph_rep = all_embeddings.sum(axis=0)
        print(graph_rep.shape)
        z = graph_rep.tolist()

        # PUT CVE CLASS
        z.append('safe')
        # print(z)

        with open(graphs_representaions_path, 'a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow(z)
        
        i+=1
